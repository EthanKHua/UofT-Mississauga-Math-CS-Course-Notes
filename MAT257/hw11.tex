\documentclass{article}
\usepackage[margin=1.0in]{geometry}
\usepackage{amssymb,amsmath,amsthm,amsfonts}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{mathtools}

% My boxes
\usepackage[breakable]{tcolorbox}

% \RequirePackage{background}
% \backgroundsetup{
%     scale=1,
%     color=black,
%     opacity=1,
%     angle=0,
%     contents={
%         \includegraphics[width=\paperwidth,height=\paperheight]{\nightmodebackground}
%     }
% }

\definecolor{pastelblue}{RGB}{96, 145, 245}
\definecolor{pastelgreen}{RGB}{106, 235, 135}
\definecolor{darkgray}{RGB}{60, 60, 60}
\definecolor{lightgray}{RGB}{180, 180, 180}
\definecolor{offwhite}{RGB}{225, 225, 245}


\pagecolor{darkgray}
\color{offwhite}

\newcommand{\Z}{\mathbf{Z}}
\newcommand{\N}{\mathbf{N}}
\newcommand{\R}{\mathbf{R}}
\newcommand{\Q}{\mathbf{Q}}
\newcommand{\C}{\mathbf{C}}

\newcommand{\id}{\mathrm{id}}
\newcommand{\op}{\mathrm{op}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\GL}{\mathrm{GL}}
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\im}{\mathrm{im}}
\newcommand{\rank}{\mathrm{rank}}

\newcommand{\cl}[1]{\overline{#1}}

\swapnumbers % places numbers before thm names

\theoremstyle{plain} % The "plain" style italicizes all body text.
	\newtheorem{thm}{Theorem}
		\numberwithin{thm}{section} % Theorem numbers are determined by section.
	\newtheorem{lemma}[thm]{Lemma}
	\newtheorem{prop}[thm]{Proposition}
	\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
    \newtheorem{defn}[thm]{Definition}
	\newtheorem{example}[thm]{Example}
	\newtheorem{exercise}[thm]{Exercise} %Exercise

\begin{document}
    \newtcolorbox{question}[2][]{fonttitle=\large, fontupper=\large, fontlower=\large, title=Question {#2}., oversize, arc=3mm, outer arc=2mm, opacityback=0.9, coltitle=offwhite, colframe=pastelblue, colback=darkgray, colupper=lightgray, collower=lightgray, leftrule=1mm, rightrule=1mm, toprule=1.5mm, titlerule=1mm, bottomrule=1mm, valign=center, add to natural height=5mm, lower separated=false, before lower=\begin{proof}, after lower= \smallbreak \end{proof}, #1, breakable=true}

    \begin{question}{30}
        Let $U\subseteq \R^n$ be an open set in $\R^n$, and let $K$ be a compact subset of $U$. Prove that there exists an \textit{infinitely differentiable} function $\varphi:\R^n\rightarrow [0,1]$ such that $\varphi(p)=1$ for all $p\in K$, and $\varphi(p)=0$ for all $p\in \R^n\setminus U$. This is called a \textbf{bump function} supported on $U$.

        (For a function $f:U\rightarrow Y$, the \textbf{$n$th total derivative} $f^{(n)}$ is defined as follows: for $n=0$, we set $f^{(0)}=f$; for $n\geq 1$, if $f^{(n-1)}$ is totally differentiable, we set $f^{(n)} = (f^{(n-1)})'$. We say that $f$ is \textbf{infinitely differentiable} if $f^{(n)}$ exists for all $n\geq 0$.)

		\tcblower
		First, we notice that the bump function in Big List \#4 can be generalised to arbitrary intervals by simply performing horizontal translations. Now, we show that bump functions for closed rectangles within open rectangles in \(\mathbb{R}^n\) can be constructed.

		Let \(R = \prod _{i=1}^n [a_i, b_i]\) be a closed rectangle that is inside an open rectangle \(S = \prod _{i=1}^n (c_i, d_i)\) in \(\mathbb{R}^n\). This implies that for all \(i\), \(c_i < a_i \leq b_i < d_i\). Considering this as an interval in \(\mathbb{R}\), we can find a bump function \(\varphi _i\) such that \(\varphi _i([a_i, b_i]) = \{1\}\) and \(\varphi _i(\mathbb{R}\setminus (c_i, d_i)) = \{0\}\). Notice that this is a function from \(\mathbb{R}\) to \(\mathbb{R}\). We define \(\alpha _i : \mathbb{R}^n \to \mathbb{R}\) by \(\alpha _i (x) = \varphi _i (x_i)\). It will be shown that the bump function supported in \(S\) is
		\[
			\beta (x) = \prod _{i=1}^n \alpha _i(x)
		\]
		First, note that each \(\alpha _i\) is infinitely differentiable, so \(\beta\) is infinitely differentiable as well. If \(p = (p_1, ..., p_n) \in R\), then for all \(i \in \{1, ..., n\}\), \(p_i \in [a_i, b_i]\), so \(\alpha _i (p) = 1\). We have
		\[
			\beta (p) = \prod _{i=1}^n \alpha _i(p) = 1
		\]
		Using a similar argument, if \(p \in \mathbb{R}^n \setminus S\), there is at least one component of \(p\) such that \(p_i \notin (c_i, d_i)\), and so \(\alpha _i(p) = 0\), which implies that
		\[
			\beta (p) = 0
		\]
		as desired.

		Additionally, if there exists bump functions \(\alpha _1\) and \(\alpha _2\) supported on open sets \(U_1\) and \(U_2\) respectively, where the compact sets are \(K_1 \subseteq U_1\) and \(K_2 \subseteq U_2\), then there exists a bump function \(\varphi\) supported on \(U_1 \cup U_2\) for the compact set \(K_1 \cup K_2\), which is defined by
		\[
			\varphi (x) = \alpha _1(x) + \alpha _2(x) - \alpha _1(x) \alpha _2(x).
		\]
		Verifying this, we see that if \(x \in K_1 \cup K_2\), then either \(x \in K_1\) or \(x \in K_2\). Assuming without loss of generality that \(x \in K_1\), we have that
		\[
			\varphi (x) = 1 + \alpha _2(x) - \alpha _2(x) = 1
		\]
		As well, if \(x \in \mathbb{R}^n \setminus (U_1 \cup U_2)\), then \(\varphi (x) = 0\), showing that \(\varphi\) is indeed a bump function.

		Next, let \(\mathbb{R}^n\) be equipped with the max-norm. We claim that \(\prod _{i=1}^n (p-r,p+r) \subseteq B(p,r)\), for \(p \in \mathbb{R}^n\) and \(r > 0\).

		Let \(x \in \prod _{i=1}^n (p-r,p+r)\). For all \(i\), \(|p_i - x_i| < r\), so \(\|x - p\| _{\max} < r\). Hence \(x \in B(p, r)\).

		Thus \(\prod _{i=1}^n (p-r,p+r) \subseteq B(p,r)\), and moreover by taking the closure of both sets,
		
		\(\prod _{i=1}^n [p-r,p+r] \subseteq \cl{B}(p,r)\).
		
		Now, we can proceed proving the main result.

		Let \(U\) be an open subset of \(\mathbb{R}^n\), and let \(K \subseteq U\) be compact. For every \(y_i \in K\), there exists an open ball centered around \(y_i\) so that \(B(y_i, \delta_i) \subseteq U\). Furthermore, we have that
		\[
			\prod _{i=1}^n \left[y_i - \frac{\delta_i}{2}, y_i + \frac{\delta_i}{2}\right] \subseteq \prod _{i=1}^n (y_i - \delta_i , y_i + \delta_i) \subseteq B(y_i, \delta_i) \subseteq U
		\]
		Let \(R_i = \prod _{i=1}^n \left[y_i - \frac{\delta_i}{2}, y_i + \frac{\delta_i}{2}\right]\) and \(S_i = \prod _{i=1}^n (y_i - \delta_i , y_i + \delta_i)\). Notice that \(\{R_i^{\circ}\}\) forms an open cover on \(K\), and by compactness, there is an finite subcover \(\{R_{i_n}^{\circ}\}_{n \leq N}\). Note that if we take the closure of each set, we get the closed cover \(\{R_{i_n}\}\).
		
		For each closed rectangle \(R_{i_n}\), we can find a bump function supported on \(S_i\). Since we have a finite number of rectangles, we can ``merge'' all the bump functions to obtain a bump function \(\gamma\) supported on \(\bigcup_{n=1}^{N} S_{i_n}\) for the compact set \(\bigcup_{n=1}^{N} K_{i_n}\). We claim that this bump function is also a bump function support on \(U\) for the compact set \(K\).

		If \(x \in K\), then it is also true that \(x \in \bigcup_{n=1}^{N} K_{i_n}\). It follows that \(\gamma (x) = 1\).

		In a similar fashion, if \(x \in \mathbb{R}^n \setminus U\), then \(x \in \mathbb{R}^n \setminus \bigcup_{n=1}^{N} S_{i_n}\), from which it follows that \(\gamma (x) = 0\).

		Therefore we have found a bump function as desired and the proof is complete.
    \end{question}
	\newpage
	\begin{question}{31}
		\begin{enumerate}[label=(\alph*)]
			\item Let $A\in M_n(\R)$ be a symmetric matrix and let $Q(\vec{x})=\vec{x}^TA\vec{x}$ be the correpsonding quadratic form. Prove that the following two statements are equivalent:
			\begin{enumerate}[label=(\roman*)]
				\item $Q(\vec{x})> 0$ for all $\vec{x}\neq \vec{0}$.
		
				\item All eigenvalues of $A$ are strictly positive.
			\end{enumerate}
		
			In this case, we say that $Q$ is a \textbf{positive definite} quadratic form, and that $A$ is a \textbf{positive definite} matrix.
		
			\item Prove the following ``stay away'' lemma, which you will need for part (c): if $Q:\R^n\rightarrow \R$ is a positive definite quadratic form, then there exists a constant $\eta>0$ such that $Q(\vec{x})\geq \eta \|\vec{x}\|^2$ for all $\vec{x}\in \R^n$.
		
			\item Let $U\subseteq\R^n$ be an open set, let $f:U\rightarrow \R$ be a twice continuously differentiable function, and let $p_0\in U$ be a point at which $\nabla f(p_0)=\vec{0}$. Prove that if the Hessian matrix $Hf(p_0)$ is positive definite, then $f$ achieves a \textbf{local minimum} at $p_0$; \textit{i.e.} $p_0$ has an open neighborhood $U_0$, contained in $U$, such that $f(p)\geq f(p_0)$ for all $p\in U_0$.
		\end{enumerate}
		\tcblower
		(a):

		Suppose that \(Q(\vec{x}) > 0\) for all \(\vec{x} \neq 0\). Since \(A\) is symmetric, it is orthogonally diagonalizable, so there exists an orthogonal matrix \(P \in M_n(\mathbb{R})\) such that \(B = P^{\top} A P\) is diagonal. Letting \(Q_B(\vec{x}) = \vec{x}^{\top} B \vec{x}\), we have that
		\[
			Q(\vec{x}) = Q_B \circ P (\vec{x})
		\]
		We will show that \(Q_B(\vec{x}) > 0\) for all \(\vec{x} \neq 0\).

		Let \(\vec{x} \in \mathbb{R}^n\) so that \(\vec{x} \neq 0\). Since \(Q(\vec{x}) > 0\), it follows that \(Q_B(\vec{x}) > 0\) as well, which implies that its eigenvalues are strictly positive. Since \(A\) and \(B\) share the same eigenvalues, we are done.

		Conversely, suppose that all the eigenvalues of \(A\) are strictly positive. By a similar argument as before, the eigenvalues of \(B\) are positive, so \(Q_B(\vec{x}) > 0\) for all \(\vec{x} \neq 0\). The same applies to \(Q\) and we are done.

		\medskip

		(b):

		First, equip \(\mathbb{R}^n\) with the 2-norm.

		Let \(Q\) be a positive definite quadratic form, so \(Q(\vec{x}) = \vec{x}^{\top}A\vec{x}\), for some diagonalizable matrix \(A\), where all its eigenvalues \(\lambda _i\) are strictly positive.
		
		Let \(\eta = \min_{1 \leq i \leq n} \{\lambda _i\}\). Let \(B\) be the diagonal matrix such that \(A = P^{\top} B P\) for an orthogonal matrix \(P\). Denote \(P(\vec{x}) = (p_1, ..., p_n)\). We have
		\[
			Q(\vec{x}) = Q_B \circ P(\vec{x}) = (P(\vec{x}))^{\top}B(P(\vec{x})) = \sum_{i=1}^{n} \lambda_i \cdot p_i^2 \geq \eta \sum_{i=1}^{n} p_i^2 = \eta \lVert P(\vec{x}) \rVert _2
		\]
		Since \(P\) preserves distance, we have that
		\[
			Q(\vec{x}) \geq \eta \lVert P(\vec{x}) \rVert _2^2 = \eta \lVert \vec{x} \rVert _2^2
		\]
		as desired.

		\medskip

		(c):

		Let \(U \subseteq \mathbb{R}^n\) be an open set, let \(f: U \to \mathbb{R}\) be a \(C^2\) function. Let \(p_0 \in U\) be a point such that \(\nabla f(p_0) = 0\). Suppose that \(Hf(p_0)\) is positive definite. We will show that \(Q(x) = \frac{1}{2}x^T Hf(p_0) x\) is a quadratic approximation to \(f\) at \(p_0\). That is,
		\[
			\lim_{h \to 0} \frac{f(p_0 + h) - f(p_0) - Q(h)}{\|h\|^2} = 0
		\]
		Let \(\varepsilon > 0\). Since \(U\) is open, there is a \(\delta _o\) so that \(p_0 + h \in U\), where \(\|h\| < \delta _o\). Additionally, by the continuity of \(Hf\), there exists \(\delta _c\) so that for \(\|h\| < \delta _c\), \(|Hf(p_0 + h) - Hf(p_0) < 2\varepsilon\). Let \(\delta = \min \{ \delta _o, \delta _c \}\). Fix \(h \in \mathbb{R}^n\) such that \(0 < \|h\| < \delta\).
		
		Since \(U\) is open, there exists \(r > 0\) so that \(p_0 + th \in U\) for \(t \in (-r, 1 + r)\). Define \(g(t) = f(p_0 + th)\).
		Applying Taylor's quadratic remainder formula to \(g\), there exists \(\theta \in (0, 1)\) so that
		\[
			g(1) = g(0) + g'(0) + \frac{1}{2}g''(\theta) \implies f(p_0 + h) = f(p_0) + f'(p_0)h + \frac{1}{2}f''(p_0 + \theta h)(h)h
		\]
		Since \(\nabla f(p_0) = 0\), we have
		\[
			f(p_0 + h) = f(p_0) + \frac{1}{2}h^T Hf(p_0 + \theta h)h
		\]
		Thus we have
		\[
			|f(p_0 + h) - f(p_0) - Q(h)| = \left\vert \frac{1}{2}h^T Hf(p_0 + \theta h)h - \frac{1}{2}h^T Hf(p_0)h\right\vert
		\]
		\[
			\leq \frac{1}{2}\|h^T\| _c \|Hf(p_0 + \theta h) - Hf(p_0)\| \|h\|
		\]
		where \(\|\cdot\| _c\) is a norm on row vectors defined by \(\|x\| _c = \|x^T\|\). Automatically we have that 
		\[
			|f(p_0 + h) - f(p_0) - Q(h)| \leq \frac{1}{2}\|Hf(p_0 + \theta h) - Hf(p_0)\| \|h\|^2 < \varepsilon \|h\|^2
		\]
		\[
			\implies \frac{f(p_0 + h) - f(p_0) - Q(h)}{\|h\|^2} < \varepsilon
		\]
		as desired. Thus \(Q\) is indeed a quadratic approximation for \(f\) at \(p_0\). It remains to show that \(f\) attains a local minimum at \(p_0\). Suppose that this is not the case. In particular, for every open neighborhood around \(p_0\) there is a point \(q\) where \(f(q) < f(p_0)\). We write \(q = p_0 + s\), where \(s = q - p_0\). Since \(Hf(p_0)\) is positive definite, \(Q\) is positive definite. Using the quadratic approximation, there is a \(\delta > 0\) so that for all \(0 < \|h\| < \delta\),
		\[
			|f(p_0 + h) - f(p_0) - Q(h)| < \eta\|h\|^2,
		\]
		where \(\eta\) comes from part (b) applied to \(Q\). Find a suitable \(s\) such that \(f(p_0 + s) < f(p_0)\). By part (a), \(Q(s) > 0\). This implies that \(f(p_0 + s) - f(p_0) - Q(s) < 0\), so
		\[
			f(p_0) - f(p_0 + s) + Q(s) < \eta \|h\|^2 \implies f(p_0) + Q(s) - \eta \|h\|^2 < f(p_0 + s).
		\]
		From part (b), we know that \(Q(s) - \eta \|h\|^2 \geq 0\), so
		\[
			f(p_0) < f(p_0 + s)
		\]
		which is a contradiction.

		Therefore we have shown that \(f\) attains a local minimum at \(p_0\) and we are done.
	\end{question}
\end{document}