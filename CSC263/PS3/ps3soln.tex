\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amssymb,amsmath,amsthm,amsfonts,mathtools}

\begin{document}
    Dear Riley,

    \medskip

    Thank you for reaching out to me and I hope you are doing well. I am writing to inform you that I have finished the task that you assigned to me. Attached to this email is the Python code I wrote to solve this problem. Additionally, I have provided an explanation for my code below, followed by the amortized complexity analyses for both the scenarios described in your email.

    \medskip

    \textbf{Implementation}

    Within the starter code I was given, I implemented the provided \texttt{insert}, \texttt{search}, and \texttt{delete} methods, where all of them use a helper method which I named \texttt{find}. I also use another helper which I named \texttt{rehash}.

    \medskip

    \textbf{Implementation of} \texttt{find}

    \texttt{find} is a method where given an array \texttt{arr}, its capacity \(c\), and a key \(k\), returns the index of this key if it already exists in the hash table, or an empty index to insert \(k\) into if it is not already in the table. First, it hashes the key using the given hash function, whose \texttt{capacity} parameter is set to \(c\). I will denote this hashed value as \(h(k)\). Then, the function checks \texttt{arr} at index \(h(k)\).
    
    If the address is unoccupied or contains the same key \(k\), then the method will return the index \(h(k)\). If not, it must be true that either another key or the DELETED string is present at this index. The reason why the method does not return the index of a DELETED string immediately is because the key \(k\) can potentially lie at another index; this is a consequence of quadratic probing. To ensure correctness, it first verifies if k exists before returning an index. The method keeps track of the index of the first DELETED occurence encountered so that it knows what to return if \(k\) is not in the hash table.
    
    Then, using quadratic probing, the method continually performs the same checks at indices \(h_i = h(k) + i^2 \pmod c\), where \(i\) is a positive integer, starting at one, that increments at each iteration. The loop stops when it finds an empty address or an address that contains the key \(k\). This algortihm is guaranteed to terminate given that the capacity of the hash table is less than half, although proving this formally is quite complex. However, I am willing to elaborate on this if need be.

    \medskip

    \textbf{Implementation of} \texttt{rehash}

    The other helper method, \texttt{rehash}, creates a new array with capacity \(c\), and iterates through the current array to reinsert the existing elements into the new array by finding a suitable address for each element using \texttt{find}, and assigning the key to that address. Particularly, \texttt{find} is called with the new array, the capacity \(c\), and each key \(k\) from the current hash table, respectively.

    \medskip

    \textbf{Implementation of} \texttt{insert}

    The \texttt{insert} method, given a key \(k\) and value \(v\), inserts the key and value into the hash table with capacity \(c\) in two steps. To start, it finds a suitable address for insertion using \texttt{find} and inserting the key-value pair \texttt{Node}\((k,v)\) in that address. If the node was inserted into an address that did not previously contain \(k\), the size attribute is incremented. If the capacity of the hash table exceeds half, the method will call \texttt{rehash} with the capacity argument equal to twice the current capacity in order to expand the hash table.

    \medskip

    \textbf{Implementation of} \texttt{search}

    Next, the \texttt{search} method takes a key \(k\) as input and attempts to return the value associated with that key. If the hash table cannot find the key, the method returns None. This method uses \texttt{find} to find the address where \(k\) would be inserted. From the implementation of \texttt{find}, the address returned is guaranteed to either be empty, DELETED, or contain the key \(k\). If the address does not contain a node, then the method returns None. Otherwise, the method will return the value in the node.

    \medskip

    \textbf{Implementation of} \texttt{delete}

    Finally, the \texttt{delete} method deletes the key \(k\) from the hash table. The implementation is very similar to \texttt{insert}. First, it attempts to find \(k\) with \texttt{find}. If \(k\) is inside the address found with \texttt{find}, replace it with the DELETED string and decrement the size attribute. Otherwise, the method does nothing. Afterwards, it checks if the capacity is below one quarter. If it has, and the maximum capacity is greater than the initial capacity, the method will call \texttt{rehash} with new capacity equal to half of the current capacity to shrink the hash table.

    That concludes the explanations for the implementation of the hash table.
    
    \medskip

    \textbf{Amortized Analyses}
    
    I will continue on with the amortized analyses of the two situations described in your email. In both situations, I will use the aggregate method to find the amortized complexity. However, for brevity's sake, I will be summarizing most of the calculations.

    \medskip

    \textbf{Situation 1}

    The first situation begins with an empty hash table with intial capacity 10, where \(N\) elements are inserted, and then \(N\) elements are deleted.

    Focusing on each insert operation first, on the \(i\)th insert, there are going to be \(i-1\) elements in the hash table already, and the worst-case situation is if all \(i\) elements---the \(i-1\) previous insertions plus the one to be inserted next---hash to the same address. This means that the \texttt{insert} method must iterate through all of the previous elements in order to find an available address. In this case, the number of array accesses is \(i\). After the insertion, if the hash table is half full, the method will need to reinsert each element into a new array with double the capacity. If this occurs, the number of accesses to the original array is \(2i\) and in the worst-case where every element hashes to the same address in the new array, inserting the \(j\)th element will take \(j\) array accesses. Our possible capacities, given that the initial capacity is 10, can be represented by \(10 \cdot 2^n\) with \(n\) being a non-negative integer. The rehashing only happens if \(i = 5 \cdot 2^n\), which is half of some potential capacity. Then if \(a_i\) is the number of array accesses made in the \(i\)th insertion operation, we can write
    \[
        a_i = \begin{dcases}
            i + 2i + \sum_{j=1}^{i} j, &\text{ if } i = 5 \cdot 2^n, \text{ for some }  n \geq 0,\\
            i, &\text{ otherwise} .
        \end{dcases}
    \]
    Note that \(5\cdot 2^n < N\), so \(n\) must be between 0 and \(\lfloor\log N - \log 5\rfloor\), where the logarithm is in base 2. Summing up all \(N\) insertions, we have that the total worst-case runtime of the insertions is
    \begin{align*}
        \sum_{i=1}^{N} a_i &= \frac{1}{2}N(N+1)+\frac{25}{2} \cdot (2^{\lfloor \log N - \log 5\rfloor + 1} - 1) + \frac{25}{2} \cdot \frac{4^{\lfloor \log N - \log 5\rfloor + 1} - 1}{3} \in \mathcal{O} (N^2)
    \end{align*}
    We can perform a very similar analysis on the \(N\) delete operations. The worst-case runtime is when every element hashes to the same address at every capacity, and each element is deleted in backwards order of the most recent rehashing. In particular, with my implementation, rehashing is done linearly, so the last key in the hash table will be inserted last, and due to open addressing, must iterate through the address of every key inserted before it. This guarantees that every other element must be checked before the method is able to access the element to be deleted. Thus we can do a very similar calculation as before to obtain that the total runtime of the delete operations is \(\mathcal{O} (N^2)\).

    Since the total cost of the operations is \(\mathcal{O} (N^2)\), the amortized cost of the sequence in the first situation is \(\mathcal{O} (N)\).

    \medskip

    \textbf{Situation 2}

    In the second situation, every insert and delete operation will require a rehashing. This is because the capacity of the hash table is one insertion away from half capacity, so after the insertion the table will be expanded. After this expansion, the capacity is at exactly one quarter, and the current capacity is not the initial capacity (which must be less than or equal to \(2N\)), and deleting an element will cause the table to shrink. After these two operations, the table returns to its previous configuration, allowing the cycle to repeat. Again, the worst-case input occurs when every element hashes to the same address, and \texttt{delete} is called on the element that is inserted last in the rehashing. This being the case, every pair of insert and delete operations will have the runtime
    \[
        \left(N + 2N + \sum_{j=1}^{N} j\right) + \left( N + 4N + \sum_{j=1}^{N-1} j \right) = N^2 + 8N.
    \]
    Since there are \(N\) pairs in total, the total cost of all operations is
    \begin{align*}
        \sum_{i=1}^{N} (N^2 + 8N) &= N^3 + 8N^2 \in \mathcal{O} (N^3).
    \end{align*}
    Thus the amortized runtime in the second situation is \(\mathcal{O} (N^2)\), which completes both the complexity analyses.
    
    I hope that my explanations and analyses were clear, and I look forward to hearing back from you soon. Thank you very much.

    \medskip

    Ethan Hua
\end{document}